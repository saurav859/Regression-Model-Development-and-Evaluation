ğŸ“Š Machine Learning Regression Project
ğŸ” Project Overview

This project focuses on building an end-to-end machine learning regression pipeline to predict a continuous target variable based on multiple numerical and categorical features.
The goal is not just high accuracy, but confirmed generalization, explainability, and deployability â€” aligned with real-world ML engineering practices.

The project covers data understanding, preprocessing, model experimentation, hyperparameter tuning, evaluation, and deployment readiness.

ğŸ¯ Problem Statement

Given structured tabular data, the objective is to:

Analyze feature distributions and relationships

Train multiple regression models

Compare performance using robust evaluation metrics

Select the most suitable model for real-world usage

ğŸ§  Machine Learning Approach
1ï¸âƒ£ Data Understanding & EDA

Dataset inspection (head, info, describe)

Missing value analysis

Distribution analysis:

Histograms for continuous variables

Bar plots for categorical variables

Correlation analysis to detect multicollinearity

2ï¸âƒ£ Data Preprocessing

Handling missing values

Encoding categorical features

Feature scaling using StandardScaler

Trainâ€“test split (80/20) to avoid data leakage

3ï¸âƒ£ Models Implemented

The following regression models were trained and evaluated:

Model	Description
Linear Regression	Baseline model to establish interpretability
Decision Tree Regressor	Captures non-linear relationships
Random Forest Regressor	Ensemble model for improved generalization

Hyperparameter tuning was performed using RandomizedSearchCV where applicable.

ğŸ“ˆ Model Evaluation

Models were evaluated using industry-standard regression metrics:

MAE (Mean Absolute Error)

MSE (Mean Squared Error)

RÂ² Score

ğŸ” Performance Comparison
Model	MAE	MSE	RÂ²
Linear Regression	0.1386	0.0349	0.9847
Decision Tree Regressor	0.1519	0.0576	0.9747
Random Forest Regressor	0.1164	0.0298	0.9869

ğŸ“Œ Random Forest Regressor was selected as the final model due to:

Lowest prediction error

Strong generalization

Stability on unseen data

ğŸš€ Deployment Readiness

Final model serialized using joblib

Scalable preprocessing pipeline

Compatible with Streamlit for interactive deployment

Clean separation of training and inference logic
